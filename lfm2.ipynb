{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "993cca73-7998-430a-a670-4dfffafe3d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from liquid_audio import LFM2AudioModel, LFM2AudioProcessor, ChatState, LFMModality\n",
    "\n",
    "# Load models\n",
    "hf_repo = \"LiquidAI/LFM2-Audio-1.5B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f23bafd-0469-4f57-9232-de65ada348b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "from jiwer import wer, cer, Compose, ToLowerCase, RemovePunctuation, RemoveMultipleSpaces, Strip\n",
    "import whisper\n",
    "\n",
    "from liquid_audio import ChatState, LFMModality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef681718-7b2e-423f-9ae5-507ed743c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"./data_librispeech\")\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True) \n",
    "DATA_ROOT = DATA_ROOT.resolve() \n",
    "OUTPUT_DIR = Path(\"./lfm2_bench_outputs\")  \n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14ff9514-6cdb-4979-a1e0-5f1b89a108b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 20\n",
    "SEED = 42\n",
    "WHISPER_MODEL_NAME = \"base\"\n",
    "GEN_MAX_NEW_TOKENS = 512\n",
    "AUDIO_TEMPERATURE = 1.0\n",
    "AUDIO_TOP_K = 4\n",
    "TARGET_SR = 24_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cbc86e6-112c-480e-b17d-97e9a4b71d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalizer():\n",
    "    return Compose([\n",
    "        ToLowerCase(),\n",
    "        RemovePunctuation(),\n",
    "        RemoveMultipleSpaces(),\n",
    "        Strip(),\n",
    "    ])\n",
    "\n",
    "def save_wav(path: Path, wav: torch.Tensor, sr: int):\n",
    "    \"\"\"\n",
    "    torchaudio.save는 [T] 또는 [C, T]만 허용.\n",
    "    - [B, C, T] → 배치 차원 제거\n",
    "    - [T, C] → [C, T]로 전치\n",
    "    - [T]  → [1, T]로 승격\n",
    "    \"\"\"\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    wav = wav.detach().cpu()\n",
    "\n",
    "    if wav.ndim == 3:           # [B, C, T] or [B, T, C] 방지\n",
    "        wav = wav.squeeze(0)    # -> 보통 [C, T] 또는 [T, C]\n",
    "    if wav.ndim == 2:\n",
    "        # time 축이 더 길다고 가정해 [C, T]로 맞춤\n",
    "        if wav.shape[0] > wav.shape[1]:  # [T, C]로 추정\n",
    "            wav = wav.transpose(0, 1)    # -> [C, T]\n",
    "    elif wav.ndim == 1:\n",
    "        wav = wav.unsqueeze(0)  # -> [1, T] (mono)\n",
    "    else:\n",
    "        raise ValueError(f\"Expected 1D or 2D (or squeezable 3D) tensor, got {wav.ndim}D tensor\")\n",
    "\n",
    "    torchaudio.save(str(path), wav, sr)\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fbb00ae-3448-4073-a906-15b41474b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_librispeech_subset(root: Path, num_samples: int, seed: int = 42):\n",
    "    \"\"\"\n",
    "    LibriSpeech test-clean에서 num_samples개만 샘플링하여 (waveform, sample_rate, transcript, utt_id) 리스트 반환\n",
    "    \"\"\"\n",
    "    from torchaudio.datasets import LIBRISPEECH\n",
    "    ds = LIBRISPEECH(root=str(root), url=\"test-clean\", download=True)\n",
    "\n",
    "    # 무작위 샘플 뽑기\n",
    "    set_seed(seed)\n",
    "    indices = list(range(len(ds)))\n",
    "    random.shuffle(indices)\n",
    "    pick = indices[:num_samples]\n",
    "\n",
    "    items = []\n",
    "    for i in pick:\n",
    "        # item: (waveform, sample_rate, transcript, speaker_id, chapter_id, utterance_id)\n",
    "        waveform, sr, transcript, spk, chap, utt = ds[i]\n",
    "        utt_id = f\"{spk}-{chap}-{utt}\"\n",
    "        items.append((waveform, sr, transcript, utt_id))\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee1583ff-f52e-4508-8fb8-bd99733a0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(hf_repo: str, device: str = None):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    processor = LFM2AudioProcessor.from_pretrained(hf_repo).eval()\n",
    "    model = LFM2AudioModel.from_pretrained(hf_repo).to(device).eval()\n",
    "    return processor, model, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80b88677-4a6f-4fed-a4f3-074eabc08b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_whisper(name: str):\n",
    "    # openai-whisper\n",
    "    return whisper.load_model(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5ed6cd2-5a6c-4b1c-a4ad-e4922a7e7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_echo_audio(processor, model, device, waveform: torch.Tensor, sr: int):\n",
    "    \"\"\"\n",
    "    입력 waveform(sr)을 넣고, 시스템 프롬프트로 '사용자 음성을 그대로, 오디오로만 반복'을 지시.\n",
    "    LFM2가 낸 오디오 토큰을 Mimi 디코더로 복원하여 (wav_24k, 24000) 반환.\n",
    "    \"\"\"\n",
    "    # 안전용: 입력 텐서를 모델 디바이스로 보낼 필요는 없음(채팅 상태는 CPU 텐서로도 동작)\n",
    "    chat = ChatState(processor)\n",
    "    chat.new_turn(\"system\")\n",
    "    chat.add_text(\"Respond in AUDIO ONLY. Repeat the user's speech verbatim without adding or removing words.\")\n",
    "    chat.end_turn()\n",
    "\n",
    "    chat.new_turn(\"user\")\n",
    "    chat.add_audio(waveform, sr)  # torchaudio.load 그대로 사용\n",
    "    chat.end_turn()\n",
    "\n",
    "    chat.new_turn(\"assistant\")\n",
    "\n",
    "    audio_tokens = []\n",
    "    for t in model.generate_interleaved(\n",
    "        **chat,\n",
    "        max_new_tokens=GEN_MAX_NEW_TOKENS,\n",
    "        audio_temperature=AUDIO_TEMPERATURE,\n",
    "        audio_top_k=AUDIO_TOP_K,\n",
    "    ):\n",
    "        if t.numel() == 1:\n",
    "            # 혹시 나오는 텍스트 토큰은 무시\n",
    "            continue\n",
    "        audio_tokens.append(t)\n",
    "\n",
    "    # 오디오 토큰이 없거나(e.g., 실패) EOS 1개만 나온 경우 방어\n",
    "    if len(audio_tokens) < 2:\n",
    "        return None, None\n",
    "\n",
    "    # 마지막 EOS 토큰 제거\n",
    "    # NOTE: mimi.decode는 CPU 텐서여도 동작하므로 굳이 model.device로 옮길 필요 없음\n",
    "    mimi_codes = torch.stack(audio_tokens[:-1], dim=1).unsqueeze(0)  # [1, T, code_dim]\n",
    "    wav_24k = processor.mimi.decode(mimi_codes)[0]  # [T]\n",
    "    return wav_24k, TARGET_SR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d44a96c-27b4-4bc1-907a-6c7cd80ccace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whisper_transcribe(whisper_model, wav: torch.Tensor, sr: int) -> str:\n",
    "    \"\"\"\n",
    "    Whisper로 (wav, sr)을 받아 적는다. 임시 wav 파일로 저장 후 transcribe 사용.\n",
    "    \"\"\"\n",
    "    tmp_path = OUTPUT_DIR / \"_tmp.wav\"\n",
    "    save_wav(tmp_path, wav, sr)\n",
    "    # Whisper는 파일 경로 입력을 주로 사용\n",
    "    result = whisper_model.transcribe(str(tmp_path), language=\"en\")\n",
    "    hyp = result.get(\"text\", \"\").strip()\n",
    "    try:\n",
    "        tmp_path.unlink()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b59493c0-7067-400b-a468-c60b46c25910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset (LibriSpeech test-clean, 20 samples)...\n",
      "Loading LFM2 and Whisper...\n",
      "[1/20] 4970-29093-15\n",
      "  - REF: YOU CAN BEGIN BY CARRYING A ROD AND PUTTING DOWN THE FIGURES\n",
      "  - HYP: You can tell why and telling tall, tall pies, then tall pies.\n",
      "  - WER: 0.833, CER: 0.617\n",
      "[2/20] 5639-40744-30\n",
      "  - REF: JUST THEN LEOCADIA CAME TO HERSELF AND EMBRACING THE CROSS SEEMED CHANGED INTO A SEA OF TEARS AND THE GENTLEMAN REMAINED...\n",
      "  - HYP: is that\n",
      "  - WER: 1.000, CER: 0.979\n",
      "[3/20] 8555-292519-11\n",
      "  - REF: HE HAD GOT INTO HER COURTYARD\n",
      "  - HYP: \n",
      "  - WER: 1.000, CER: 1.000\n",
      "[4/20] 121-127105-34\n",
      "  - REF: IT SOUNDED DULL IT SOUNDED STRANGE AND ALL THE MORE SO BECAUSE OF HIS MAIN CONDITION WHICH WAS\n",
      "  - HYP: One, two, three, four, one, one, one.\n",
      "  - WER: 1.000, CER: 0.787\n",
      "[5/20] 8555-284447-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [32,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [33,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [34,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [35,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [36,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [37,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [38,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [39,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [40,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [41,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [42,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [43,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [44,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [45,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [46,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [47,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [48,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [49,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [50,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [51,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [52,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [53,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [54,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [55,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [56,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [57,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [58,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [59,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [60,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [61,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [62,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [63,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [0,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [1,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [2,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [3,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [4,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [5,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [6,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [7,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [8,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [9,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [10,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [11,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [12,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [13,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [14,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [15,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [16,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [17,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [18,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [19,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [20,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [21,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [22,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [23,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [24,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [25,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [26,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [27,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [28,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [29,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [30,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [24,0,0], thread: [31,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nSearch for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     54\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo results to summarize (no audio generated or an error occurred).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(items)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mutt_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# 1) LFM2로 오디오→오디오 (echo) 생성\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m gen_wav, gen_sr = \u001b[43mgenerate_echo_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gen_wav \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  - No audio generated. Skipping.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mgenerate_echo_audio\u001b[39m\u001b[34m(processor, model, device, waveform, sr)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# 마지막 EOS 토큰 제거\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# NOTE: mimi.decode는 CPU 텐서여도 동작하므로 굳이 model.device로 옮길 필요 없음\u001b[39;00m\n\u001b[32m     37\u001b[39m mimi_codes = torch.stack(audio_tokens[:-\u001b[32m1\u001b[39m], dim=\u001b[32m1\u001b[39m).unsqueeze(\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# [1, T, code_dim]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m wav_24k = \u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmimi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmimi_codes\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# [T]\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wav_24k, TARGET_SR\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/liquid_audio/moshi/models/compression.py:420\u001b[39m, in \u001b[36mMimiModel.decode\u001b[39m\u001b[34m(self, codes)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.decoder_transformer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    419\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m         (emb,) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    422\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m state.graphed_tr_dec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/liquid_audio/moshi/modules/transformer.py:950\u001b[39m, in \u001b[36mProjectedTransformer.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.input_proj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    949\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.input_proj(x)\n\u001b[32m--> \u001b[39m\u001b[32m950\u001b[39m z = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    951\u001b[39m ys = []\n\u001b[32m    952\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m output_proj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_projs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/liquid_audio/moshi/modules/transformer.py:896\u001b[39m, in \u001b[36mStreamingTransformer.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    894\u001b[39m         x = y\n\u001b[32m    895\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m896\u001b[39m         x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    899\u001b[39m     state.offsets[:] = torch.where(\n\u001b[32m    900\u001b[39m         state.exec_mask,\n\u001b[32m    901\u001b[39m         state.offsets + T,\n\u001b[32m    902\u001b[39m         state.offsets)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/liquid_audio/moshi/modules/transformer.py:767\u001b[39m, in \u001b[36mStreamingTransformerLayer.forward\u001b[39m\u001b[34m(self, x, cross_attention_src)\u001b[39m\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.device.type != \u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    766\u001b[39m     stack.enter_context(no_compile())\n\u001b[32m--> \u001b[39m\u001b[32m767\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cross_attention \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m cross_attention_src \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/liquid_audio/moshi/modules/transformer.py:751\u001b[39m, in \u001b[36mStreamingTransformerLayer._sa_block\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    749\u001b[39m x_orig = x\n\u001b[32m    750\u001b[39m x = \u001b[38;5;28mself\u001b[39m.norm1(x)\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m update = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x_orig.to(update) + \u001b[38;5;28mself\u001b[39m.layer_scale_1(update)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/liquid_audio/moshi/modules/transformer.py:562\u001b[39m, in \u001b[36mStreamingMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    561\u001b[39m     attn_bias = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m x = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m x = rearrange(x, \u001b[33m\"\u001b[39m\u001b[33mb h t d -> b t (h d)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    565\u001b[39m x = apply_weights_per_step(\n\u001b[32m    566\u001b[39m     \u001b[38;5;28mself\u001b[39m.out_projs, \u001b[38;5;28mself\u001b[39m.weights_per_step_schedule, x, offset_cpu)\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: device-side assert triggered\nSearch for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    set_seed(SEED)\n",
    "\n",
    "    print(\"Loading dataset (LibriSpeech test-clean, 20 samples)...\")\n",
    "    items = load_librispeech_subset(DATA_ROOT, NUM_SAMPLES, SEED)\n",
    "\n",
    "    print(\"Loading LFM2 and Whisper...\")\n",
    "    processor, model, device = load_models(hf_repo)\n",
    "    asr = load_whisper(WHISPER_MODEL_NAME)\n",
    "\n",
    "    tn = text_normalizer()\n",
    "\n",
    "    wer_list = []\n",
    "    cer_list = []\n",
    "\n",
    "    for idx, (waveform, sr, ref_text, utt_id) in enumerate(items, 1):\n",
    "        print(f\"[{idx}/{len(items)}] {utt_id}\")\n",
    "\n",
    "        # 1) LFM2로 오디오→오디오 (echo) 생성\n",
    "        gen_wav, gen_sr = generate_echo_audio(processor, model, device, waveform, sr)\n",
    "        if gen_wav is None:\n",
    "            print(\"  - No audio generated. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # 2) 생성 오디오를 저장 (옵션)\n",
    "        out_path = OUTPUT_DIR / f\"{utt_id}_gen.wav\"\n",
    "        save_wav(out_path, gen_wav, gen_sr) \n",
    "\n",
    "        # 3) Whisper로 생성 오디오 전사\n",
    "        hyp_text = whisper_transcribe(asr, gen_wav, gen_sr)\n",
    "\n",
    "        # 4) 정규화 후 WER/CER 계산\n",
    "        ref_norm = tn(ref_text)\n",
    "        hyp_norm = tn(hyp_text)\n",
    "\n",
    "        s_wer = wer(ref_norm, hyp_norm)\n",
    "        s_cer = cer(ref_norm, hyp_norm)\n",
    "\n",
    "        wer_list.append(s_wer)\n",
    "        cer_list.append(s_cer)\n",
    "\n",
    "        print(f\"  - REF: {ref_text[:120]}{'...' if len(ref_text)>120 else ''}\")\n",
    "        print(f\"  - HYP: {hyp_text[:120]}{'...' if len(hyp_text)>120 else ''}\")\n",
    "        print(f\"  - WER: {s_wer:.3f}, CER: {s_cer:.3f}\")\n",
    "\n",
    "    if wer_list:\n",
    "        avg_wer = sum(wer_list) / len(wer_list)\n",
    "        avg_cer = sum(cer_list) / len(cer_list)\n",
    "        print(\"\\n==== Summary (Echo Audio-to-Audio, 20 samples) ====\")\n",
    "        print(f\"Avg WER: {avg_wer:.3f}\")\n",
    "        print(f\"Avg CER: {avg_cer:.3f}\")\n",
    "        print(f\"Saved generated audio to: {OUTPUT_DIR.resolve()}\")\n",
    "    else:\n",
    "        print(\"No results to summarize (no audio generated or an error occurred).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "171549d6-65ec-46d9-ace3-78db4234ce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any parent up to mount point /root)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!git add untitled2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a098db91-2aec-4c08-a610-b942b414a45c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
